{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "b6bc7b80-5fc9-479d-87aa-2151a3dd17db",
   "metadata": {},
   "outputs": [],
   "source": [
    " \"\"\"\n",
    "        @Author: Alexander Pabel\n",
    "\"\"\"\n",
    "import os\n",
    "from PIL import Image\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms\n",
    "import torch.optim as optim\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "506ca44a-8e3e-48c2-9e99-4ab6e0bdf0b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Bilder augmentieren fürs Training und die Evaluation\n",
    "train_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.RandomHorizontalFlip(),\n",
    "    transforms.RandomRotation(10),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])\n",
    "\n",
    "val_transforms = transforms.Compose([\n",
    "    transforms.Resize((128, 128)),\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "2a369169-7d47-4389-9fcd-e8c52c30bbf3",
   "metadata": {},
   "outputs": [],
   "source": [
    "class catDogImageDataset(Dataset):\n",
    "    def __init__(self, root_dir, transform=None):\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.image_paths = []\n",
    "        self.labels = []\n",
    "        self.class_to_idx = {'cats': 0, 'dogs': 1}\n",
    "        \n",
    "        for label in os.listdir(root_dir):\n",
    "            class_dir = os.path.join(root_dir, label)\n",
    "            if os.path.isdir(class_dir):\n",
    "                for img_name in os.listdir(class_dir):\n",
    "                    self.image_paths.append(os.path.join(class_dir, img_name))\n",
    "                    self.labels.append(self.class_to_idx[label])\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.image_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.image_paths[idx]\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        label = self.labels[idx]\n",
    "\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "\n",
    "        return image, label\n",
    "\n",
    "train_dataset = catDogImageDataset(root_dir='dataset/train', transform=train_transforms)\n",
    "val_dataset = catDogImageDataset(root_dir='dataset/val', transform=val_transforms)\n",
    "train_loader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
    "val_loader = DataLoader(val_dataset, batch_size=32, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "471093f0-6fc2-4d9b-8ca2-90141495d500",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Durch den ResidualBlock wird das Problem der verschwindenden Gradienten behoben, was das Erlernen komplexerer Features ermoeglicht\n",
    "class ResidualBlock(nn.Module):\n",
    "    def __init__(self, in_channels, out_channels, stride=1):\n",
    "        super(ResidualBlock, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(in_channels, out_channels, kernel_size=3, stride=stride, padding=1, bias=False)\n",
    "        self.bn1 = nn.BatchNorm2d(out_channels)\n",
    "        self.conv2 = nn.Conv2d(out_channels, out_channels, kernel_size=3, stride=1, padding=1, bias=False)\n",
    "        self.bn2 = nn.BatchNorm2d(out_channels)\n",
    "        self.shortcut = nn.Sequential()\n",
    "        if stride != 1 or in_channels != out_channels:\n",
    "            self.shortcut = nn.Sequential(\n",
    "                nn.Conv2d(in_channels, out_channels, kernel_size=1, stride=stride, bias=False),\n",
    "                nn.BatchNorm2d(out_channels)\n",
    "            )\n",
    "    #Dies geschieht ueber einen Shortcut\n",
    "    def forward(self, x):\n",
    "        out = F.relu(self.bn1(self.conv1(x)))\n",
    "        out = self.bn2(self.conv2(out))\n",
    "        out += self.shortcut(x)\n",
    "        out = F.relu(out)\n",
    "        return out\n",
    "        \n",
    "class CatDogClassifierResNet(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(CatDogResNet, self).__init__()\n",
    "        self.initial = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, kernel_size=3, stride=1, padding=1, bias=False),\n",
    "            nn.BatchNorm2d(32),\n",
    "            nn.ReLU()\n",
    "        )\n",
    "        self.layer1 = self._make_layer(32, 64, stride=2)\n",
    "        self.layer2 = self._make_layer(64, 128, stride=2)\n",
    "        self.layer3 = self._make_layer(128, 256, stride=2)\n",
    "        \n",
    "        self.fc = nn.Sequential(\n",
    "            nn.Linear(256 * 4 * 4, 512),  # Match final feature map size\n",
    "            nn.Dropout(p=0.5),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(512, 2)\n",
    "        )\n",
    "\n",
    "    def _make_layer(self, in_channels, out_channels, stride):\n",
    "        return nn.Sequential(\n",
    "            ResidualBlock(in_channels, out_channels, stride),\n",
    "            ResidualBlock(out_channels, out_channels)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        x = self.initial(x)\n",
    "        x = self.layer1(x)\n",
    "        x = self.layer2(x)\n",
    "        x = self.layer3(x)\n",
    "        x = F.avg_pool2d(x, 4)  # Global Average Pooling\n",
    "        x = x.view(x.size(0), -1)\n",
    "        x = self.fc(x)\n",
    "        return x\n",
    "\n",
    "\n",
    "model = CatDogClassifierResNet()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "bc7ab2f3-0b68-4dac-9b44-2784ad94a164",
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "#Criterion für Fehlerberechnung,Gradientenberechnung und Backpropagation\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "#Optimierer\n",
    "optimizer = optim.Adam(model.parameters(), lr=0.001, weight_decay=0.0001)\n",
    "\n",
    "num_epochs = 50 \n",
    "\n",
    "best_val_loss = float('inf')\n",
    "patience = 10  # Number of epochs to wait before stopping\n",
    "epochs_without_improvement = 0\n",
    "\n",
    "#Training des Modells\n",
    "for epoch in range(num_epochs):\n",
    "    model.train()\n",
    "    running_loss = 0.0\n",
    "    \n",
    "    for inputs, labels in train_loader:\n",
    "        optimizer.zero_grad()\n",
    "        outputs = model(inputs)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        running_loss += loss.item()\n",
    "    \n",
    "    print(f\"Epoch {epoch+1}/{num_epochs}, Loss: {running_loss/len(train_loader)}\")\n",
    "\n",
    "    model.eval()\n",
    "    val_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    with torch.no_grad():\n",
    "        for inputs, labels in val_loader:\n",
    "            outputs = model(inputs)\n",
    "            loss = criterion(outputs, labels)\n",
    "            val_loss += loss.item()\n",
    "            _, predicted = torch.max(outputs, 1)\n",
    "            total += labels.size(0)\n",
    "            correct += (predicted == labels).sum().item()\n",
    "\n",
    "    print(f\"Validation Loss: {val_loss/len(val_loader)}, Accuracy: {100 * correct / total}%\")\n",
    "    if val_loss < best_val_loss:\n",
    "        best_val_loss = val_loss\n",
    "        epochs_without_improvement = 0\n",
    "        torch.save(model.state_dict(), 'best_model.pth')\n",
    "    else:\n",
    "        epochs_without_improvement += 1\n",
    "\n",
    "    if epochs_without_improvement >= patience:\n",
    "        print(\"Early stopping\")\n",
    "\n",
    "        break"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
